// prettier-ignore
export type KnownModel_Type =
    | "TAESD"              // x   8
    | "upscale"            // x  11
    | "checkpoint"         // x  37
    | "insightface"        // x  13
    | "deepbump"           // x   1
    | "face_restore"       // x   3
    | "zero123"            // x   5
    | "embeddings"         // x   4
    | "VAE"                // x   8
    | "diffusion_model"    // x  45
    | "clip"               // x  21
    | "lora"               // x  35
    | "unclip"             // x   2
    | "T2I-Adapter"        // x  18
    | "T2I-Style"          // x   1
    | "controlnet"         // x  70
    | "clip_vision"        // x   6
    | "gligen"             // x   1
    | "sam"                // x   4
    | "seecoder"           // x   3
    | "Ultralytics"        // x  16
    | "animatediff"        // x  13
    | "motion lora"        // x   8
    | "IP-Adapter"         // x  25
    | "PFG"                // x   3
    | "GFPGAN"             // x   1
    | "CodeFormer"         // x   1
    | "facexlib"           // x   4
    | "photomaker"         // x   2
    | "instantid"          // x   2
    | "efficient_sam"      // x   2
    | "Shape Predictor"    // x   1
    | "Face Recognition"   // x   1
    | "InstanceDiffusion"  // x   3
    | "BLIP_MODEL"         // x   1
    | "GroundingDINO"      // x   2
    | "RAM"                // x   3
    | "IC-Light"           // x   3
    | "ID-Animator"        // x   3
    | "CustomNet"          // x   1
    | "RGT"                // x   6
    | "depthanything"      // x   6
    | "SegGPT"             // x   1
    | "depth-pro"          // x   1
    | "LLM"                // x   3
    | "PuLID"              // x   2
    | "MoGe"               // x   2

export const knownModel_Type: KnownModel_Type[] = [
    "TAESD"             ,  // x   8
    "upscale"           ,  // x  11
    "checkpoint"        ,  // x  37
    "insightface"       ,  // x  13
    "deepbump"          ,  // x   1
    "face_restore"      ,  // x   3
    "zero123"           ,  // x   5
    "embeddings"        ,  // x   4
    "VAE"               ,  // x   8
    "diffusion_model"   ,  // x  45
    "clip"              ,  // x  21
    "lora"              ,  // x  35
    "unclip"            ,  // x   2
    "T2I-Adapter"       ,  // x  18
    "T2I-Style"         ,  // x   1
    "controlnet"        ,  // x  70
    "clip_vision"       ,  // x   6
    "gligen"            ,  // x   1
    "sam"               ,  // x   4
    "seecoder"          ,  // x   3
    "Ultralytics"       ,  // x  16
    "animatediff"       ,  // x  13
    "motion lora"       ,  // x   8
    "IP-Adapter"        ,  // x  25
    "PFG"               ,  // x   3
    "GFPGAN"            ,  // x   1
    "CodeFormer"        ,  // x   1
    "facexlib"          ,  // x   4
    "photomaker"        ,  // x   2
    "instantid"         ,  // x   2
    "efficient_sam"     ,  // x   2
    "Shape Predictor"   ,  // x   1
    "Face Recognition"  ,  // x   1
    "InstanceDiffusion" ,  // x   3
    "BLIP_MODEL"        ,  // x   1
    "GroundingDINO"     ,  // x   2
    "RAM"               ,  // x   3
    "IC-Light"          ,  // x   3
    "ID-Animator"       ,  // x   3
    "CustomNet"         ,  // x   1
    "RGT"               ,  // x   6
    "depthanything"     ,  // x   6
    "SegGPT"            ,  // x   1
    "depth-pro"         ,  // x   1
    "LLM"               ,  // x   3
    "PuLID"             ,  // x   2
    "MoGe"              ,  // x   2
]

